services:
  gemma-3-4b-executor:
    image: skyscopeai/model-executor
    environment:
      EXECUTOR_TYPE: huggingface
      EXECUTOR_ACCESS_CODE: .model/google/gemma-3
      EXECUTOR_NAME: Gemma 3 4B
      EXECUTOR_IMAGE: gemma.png # Refer to src/multi-chat/public/images
      EXECUTOR_ORDER: 301000
      HUGGING_FACE_HUB_TOKEN: ${HUGGING_FACE_HUB_TOKEN}
    depends_on:
      - executor-builder
      - kernel
      - multi-chat
    command: [
      "--model_path", "google/gemma-3-4b-it",
      "--visible_gpu", "0",
      # "--load_8bits",
      "--device_map", "cpu",
      "--log", "debug",
    ]
    restart: unless-stopped
    volumes: ["~/.cache/huggingface:/root/.cache/huggingface"]
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #       - driver: nvidia
    #         device_ids: ['0']
    #         capabilities: [gpu]
    extra_hosts:
      - "localhost:host-gateway"
    networks: ["backend"]
